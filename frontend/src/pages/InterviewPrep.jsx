import React, { useState, useRef, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import RecordRTC from "recordrtc";
import { useMediaQuery } from "react-responsive"; // Import for responsive handling
import { ChevronDown, ChevronUp } from "lucide-react"; // Import icons

// ---- SAMPLE DATA ----
const sampleJobs = [
  {
    id: 1,
    company_name: "TechNova Solutions",
    job_title: "Software Engineer",
    job_description:
      "Develop and maintain scalable software solutions for our clients.",
    required_skills: ["JavaScript", "React", "Node.js", "MongoDB", "REST APIs"],
    location: "San Francisco, CA (Hybrid)",
  },
  {
    id: 2,
    company_name: "GreenEarth Innovations",
    job_title: "Sustainability Analyst",
    job_description:
      "Analyze company operations to identify areas for sustainability improvements.",
    required_skills: ["Data analysis", "Sustainability reporting"],
    location: "Remote",
  },
];

const sampleResume = {
  softskills: ["Communication", "Teamwork", "Problem-Solving"],
  resumeText:
    "An experienced software engineer with a passion for building scalable applications.",
  skills: ["JavaScript", "Node.js", "MongoDB", "React"],
  experience: [
    {
      company: "Tech Solutions Inc.",
      position: "Software Engineer",
      startDate: "2020-01-01T00:00:00.000Z",
      endDate: "2023-06-01T00:00:00.000Z",
      description: "Worked on various backend services and APIs.",
    },
  ],
  education: [
    {
      institution: "University of Technology",
      degree: "Bachelor of Science",
      fieldOfStudy: "Computer Science",
      startYear: 2012,
      endYear: 2016,
      grade: "3.7 GPA",
    },
  ],
  coCurricular: ["Hackathons", "Open Source Contributions"],
  certifications: [
    {
      name: "AWS Certified Developer",
      issuer: "Amazon Web Services",
      date: "2022-05-15T00:00:00.000Z",
      credentials: "aws-cert-12345",
    },
  ],
  projects: [
    {
      title: "Portfolio Website",
      description: "A personal website showcasing projects and blogs.",
      link: "https://johndoe.dev",
    },
  ],
  summary:
    "Driven software engineer with a proven track record of delivering robust solutions.",
  linkedin: "https://linkedin.com/in/johndoe",
  profileLinks: [
    { platform: "GitHub", url: "https://github.com/johndoe" },
    { platform: "Twitter", url: "https://twitter.com/johndoe" },
  ],
};
// ---- END SAMPLE DATA ----

// ---- BODY LANGUAGE ANALYZER ----
class BodyLanguageAnalyzer {
  constructor() {
    this.audioContext = null;
    this.analyzer = null;
    this.isInitialized = false;
  }

  async initialize() {
    try {
      // Initialize audio context for tone analysis
      this.audioContext = new (window.AudioContext ||
        window.webkitAudioContext)();
      this.analyzer = this.audioContext.createAnalyser();
      this.analyzer.fftSize = 2048;

      this.isInitialized = true;
      console.log("ü§ñ Body language analyzer initialized");
    } catch (error) {
      console.error("Failed to initialize analyzer:", error);
    }
  }

  analyzePosture(videoElement) {
    if (!this.isInitialized || !videoElement) return null;

    // Simple posture analysis (mock data for now - can be enhanced with ML models)
    const analysis = {
      posture: this.calculatePostureScore(),
      eyeContact: this.estimateEyeContact(),
      handGestures: this.analyzeHandGestures(),
      facialExpression: this.analyzeFacialExpression(),
    };

    return analysis;
  }

  analyzeAudioTone(audioStream) {
    if (!this.audioContext || !audioStream) return null;

    try {
      const source = this.audioContext.createMediaStreamSource(audioStream);
      source.connect(this.analyzer);

      const bufferLength = this.analyzer.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      this.analyzer.getByteFrequencyData(dataArray);

      // Analyze tone characteristics
      return {
        pitch: this.calculatePitch(dataArray),
        volume: this.calculateVolume(dataArray),
        clarity: this.calculateClarity(dataArray),
        pace: this.calculateSpeechPace(dataArray),
      };
    } catch (error) {
      console.error("Audio analysis error:", error);
      return null;
    }
  }

  calculatePostureScore() {
    return Math.floor(Math.random() * 40) + 60; // Mock score 60-100
  }

  estimateEyeContact() {
    return Math.floor(Math.random() * 30) + 70; // Mock score 70-100
  }

  analyzeHandGestures() {
    const gestures = ["calm", "expressive", "fidgeting", "professional"];
    return gestures[Math.floor(Math.random() * gestures.length)];
  }

  analyzeFacialExpression() {
    const expressions = ["confident", "nervous", "engaged", "neutral"];
    return expressions[Math.floor(Math.random() * expressions.length)];
  }

  calculatePitch(dataArray) {
    const sum = dataArray.reduce((a, b) => a + b, 0);
    return Math.floor((sum / dataArray.length) * 100) / 255;
  }

  calculateVolume(dataArray) {
    const sum = dataArray.reduce((a, b) => a + b, 0);
    return Math.floor((sum / dataArray.length) * 100) / 255;
  }

  calculateClarity(dataArray) {
    return Math.floor(Math.random() * 20) + 80; // Mock score
  }

  calculateSpeechPace(dataArray) {
    const speeds = ["too slow", "perfect", "too fast", "good"];
    return speeds[Math.floor(Math.random() * speeds.length)];
  }

  generateRealTimeFeedback(bodyAnalysis, audioAnalysis) {
    const feedback = [];

    if (bodyAnalysis?.posture < 70) {
      feedback.push("üîÑ Sit up straighter for better presence");
    }
    if (bodyAnalysis?.eyeContact < 75) {
      feedback.push("üëÅÔ∏è Try to look more directly at the camera");
    }
    if (audioAnalysis?.volume < 50) {
      feedback.push("üîä Speak a bit louder");
    }
    if (audioAnalysis?.volume > 80) {
      feedback.push("üîâ Lower your voice slightly");
    }
    if (audioAnalysis?.pace === "too fast") {
      feedback.push("‚è≥ Slow down your speech pace");
    }
    if (audioAnalysis?.pace === "too slow") {
      feedback.push("‚ö° Speed up your speech a bit");
    }

    return feedback;
  }
}

const bodyLanguageAnalyzer = new BodyLanguageAnalyzer();

const InterviewPrep = () => {
  const isMobile = useMediaQuery({ maxWidth: 768 }); // Detect mobile screens

  // EXISTING STATE
  const [jobs, setJobs] = useState([]);
  const [resume, setResume] = useState(null);
  const [selectedJob, setSelectedJob] = useState(null);
  const [questions, setQuestions] = useState([]);
  const [step, setStep] = useState(0); // 0: select, 1: interview, 2: review
  const [currentQ, setCurrentQ] = useState(0);
  const [answers, setAnswers] = useState([]);
  const [recording, setRecording] = useState(false);
  const [mediaBlobs, setMediaBlobs] = useState([]);
  const [timer, setTimer] = useState(0);
  const recorderRef = useRef(null);
  const videoRef = useRef(null);
  const [feedback, setFeedback] = useState(null);
  const timerInterval = useRef(null);

  // EXISTING SPEECH RECOGNITION
  const [transcript, setTranscript] = useState("");
  const [isListening, setIsListening] = useState(false);
  const recognitionRef = useRef(null);
  const transcriptRef = useRef("");

  // NEW: Body language and tone analysis state
  const [bodyLanguageAnalysis, setBodyLanguageAnalysis] = useState(null);
  const [audioAnalysis, setAudioAnalysis] = useState(null);
  const [realTimeFeedback, setRealTimeFeedback] = useState([]);
  const [analysisEnabled, setAnalysisEnabled] = useState(false);
  const analysisInterval = useRef(null);
  const [audioStream, setAudioStream] = useState(null);

  // EXISTING SPEECH RECOGNITION SETUP
  useEffect(() => {
    if (
      !("webkitSpeechRecognition" in window || "SpeechRecognition" in window)
    ) {
      console.warn("SpeechRecognition not supported in this browser.");
      return;
    }

    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();

    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = "en-US";
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      console.log("üé§ Speech recognition started");
      setIsListening(true);
    };

    recognition.onresult = (event) => {
      console.log("üìù Speech result received");
      let finalTranscript = "";
      let interimTranscript = "";

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcriptPart = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcriptPart + " ";
          console.log("‚úÖ Final:", transcriptPart);
        } else {
          interimTranscript += transcriptPart;
          console.log("‚è≥ Interim:", transcriptPart);
        }
      }

      if (finalTranscript) {
        setTranscript((prev) => prev + finalTranscript);
        transcriptRef.current += finalTranscript + " ";
      }

      if (interimTranscript) {
        setTranscript((prev) => {
          const baseTxt = prev.replace(/ \[speaking\.\.\.\].*/, "");
          return baseTxt + " [speaking...] " + interimTranscript;
        });
      }
    };

    recognition.onerror = (event) => {
      console.error("‚ùå Speech error:", event.error);
      if (event.error === "no-speech") {
        console.log("üîÑ Restarting due to no-speech...");
        setTimeout(() => {
          if (recording && recognitionRef.current) {
            recognitionRef.current.start();
          }
        }, 1000);
      }
      setIsListening(false);
    };

    recognition.onend = () => {
      console.log("üõë Speech recognition ended");
      setIsListening(false);
      if (recording) {
        console.log("üîÑ Auto-restarting recognition...");
        setTimeout(() => {
          if (recording && recognitionRef.current) {
            recognitionRef.current.start();
          }
        }, 500);
      }
    };

    recognitionRef.current = recognition;

    return () => {
      if (recognition) {
        recognition.stop();
      }
    };
  }, [recording]);

  // NEW: Initialize body language analyzer
  useEffect(() => {
    const initAnalyzer = async () => {
      await bodyLanguageAnalyzer.initialize();
    };
    initAnalyzer();
  }, []);

  // NEW: Real-time analysis during recording
  useEffect(() => {
    if (recording && analysisEnabled) {
      analysisInterval.current = setInterval(() => {
        performRealTimeAnalysis();
      }, 2000); // Analyze every 2 seconds
    } else {
      if (analysisInterval.current) {
        clearInterval(analysisInterval.current);
      }
    }

    return () => {
      if (analysisInterval.current) {
        clearInterval(analysisInterval.current);
      }
    };
  }, [recording, analysisEnabled]);

  const performRealTimeAnalysis = () => {
    if (!videoRef.current || !analysisEnabled) return;

    // Analyze body language
    const bodyAnalysis = bodyLanguageAnalyzer.analyzePosture(videoRef.current);
    setBodyLanguageAnalysis(bodyAnalysis);

    // Analyze audio tone
    const audioAnalysisResult =
      bodyLanguageAnalyzer.analyzeAudioTone(audioStream);
    setAudioAnalysis(audioAnalysisResult);

    // Generate real-time feedback
    const feedback = bodyLanguageAnalyzer.generateRealTimeFeedback(
      bodyAnalysis,
      audioAnalysisResult
    );
    setRealTimeFeedback(feedback);
  };

  // EXISTING: Fetch jobs and resume
  useEffect(() => {
    const fetchData = async () => {
      let jobsData = sampleJobs;
      let resumeData = sampleResume;
      try {
        const user = JSON.parse(localStorage.getItem("firebaseUser"));
        const firebaseUid = user?.uid || localStorage.getItem("firebaseUid");
        if (firebaseUid) {
          const jobsRes = await fetch(
            `${import.meta.env.VITE_API_URL}/jobs/wishlist/user/${firebaseUid}`
          );
          const jobsJson = await jobsRes.json();
          if (Array.isArray(jobsJson.wishlist) && jobsJson.wishlist.length > 0)
            jobsData = jobsJson.wishlist;
        }
      } catch {}
      try {
        const resumeRes = await fetch(
          `${import.meta.env.VITE_API_URL}/profile/resume`,
          {
            headers: {
              Authorization: `Bearer ${localStorage.getItem("authToken")}`,
            },
          }
        );
        const resumeJson = await resumeRes.json();
        if (resumeJson.resume) resumeData = resumeJson.resume;
      } catch {}
      setJobs(jobsData);
      setResume(resumeData);
    };
    fetchData();
  }, []);

  // EXISTING: Initialize interview
  const startInterview = async () => {
    try {
      const res = await fetch(
        `${import.meta.env.VITE_API_URL}/interview/questions`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            job: selectedJob,
            resume,
          }),
        }
      );
      const data = await res.json();
      let qs = [];
      if (Array.isArray(data.questions) && data.questions.length > 0) {
        qs = data.questions;
        setQuestions(qs);
      } else {
        qs = [
          "Tell me about yourself.",
          "Describe a challenging project you worked on.",
          "How do you handle tight deadlines?",
          "What is your experience with React?",
          "Why do you want to work at this company?",
        ];
        setQuestions(qs);
      }
      setAnswers(
        qs.map((q) => ({
          question: q,
          textAnswer: "",
          transcript: "",
          timeTaken: 0,
        }))
      );
    } catch {
      const qs = [
        "Tell me about yourself.",
        "Describe a challenging project you worked on.",
        "How do you handle tight deadlines?",
        "What is your experience with React?",
        "Why do you want to work at this company?",
      ];
      setQuestions(qs);
      setAnswers(
        qs.map((q) => ({
          question: q,
          textAnswer: "",
          transcript: "",
          timeTaken: 0,
        }))
      );
    }
    setStep(1);
    setCurrentQ(0);
    setMediaBlobs([]);
    setTranscript("");
    transcriptRef.current = "";
  };

  // ENHANCED: Start recording with analysis
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      setAudioStream(stream);
      videoRef.current.srcObject = stream;
      recorderRef.current = new RecordRTC(stream, { type: "video" });
      recorderRef.current.startRecording();
      setRecording(true);
      setTimer(0);
      setTranscript("");
      transcriptRef.current = "";

      // Reset analysis data
      setBodyLanguageAnalysis(null);
      setAudioAnalysis(null);
      setRealTimeFeedback([]);

      timerInterval.current = setInterval(() => {
        setTimer((t) => t + 1);
      }, 1000);

      setTimeout(() => {
        if (recognitionRef.current) {
          console.log("üöÄ Starting speech recognition...");
          recognitionRef.current.start();
        }
      }, 500);
    } catch (error) {
      console.error("Error starting recording:", error);
    }
  };

  // ENHANCED: Stop recording with analysis
  const stopRecording = async () => {
    if (recognitionRef.current) {
      console.log("üõë Stopping speech recognition...");
      recognitionRef.current.stop();
    }

    // Stop analysis
    if (analysisInterval.current) {
      clearInterval(analysisInterval.current);
    }

    const cleanedTranscript = transcriptRef.current
      .replace(/ \[speaking\.\.\.\].*/, "")
      .trim();
    console.log("üíæ Saving transcript:", cleanedTranscript);

    // Get current textarea value
    const currentTextValue = document.querySelector("textarea")?.value || "";

    // ENHANCED: Save analysis data with answer
    setAnswers((prev) => {
      const copy = [...prev];
      copy[currentQ] = {
        ...copy[currentQ],
        question: questions[currentQ],
        timeTaken: timer,
        transcript: cleanedTranscript,
        textAnswer: currentTextValue || cleanedTranscript,
        bodyLanguageAnalysis: bodyLanguageAnalysis,
        audioAnalysis: audioAnalysis,
        realTimeFeedback: realTimeFeedback,
      };
      return copy;
    });

    if (recorderRef.current) {
      await new Promise((resolve) => {
        recorderRef.current.stopRecording(() => {
          const blob = recorderRef.current.getBlob();
          setMediaBlobs((prev) => [...prev, blob]);
          resolve();
        });
      });
    }

    clearInterval(timerInterval.current);
    setRecording(false);
    setIsListening(false);

    if (videoRef.current?.srcObject) {
      let tracks = videoRef.current.srcObject.getTracks();
      tracks.forEach((track) => track.stop());
    }
    setAudioStream(null);
  };

  // EXISTING: Handle next question
  const handleNext = async () => {
    if (recording) {
      await stopRecording();
    }

    setCurrentQ((q) => q + 1);
    setTimer(0);
    setTranscript("");
    transcriptRef.current = "";
  };

  // EXISTING: Handle answer change
  const handleAnswerChange = (e) => {
    const value = e.target.value;
    setAnswers((prev) => {
      const copy = [...prev];
      copy[currentQ] = {
        ...copy[currentQ],
        question: questions[currentQ],
        textAnswer: value,
        transcript: copy[currentQ]?.transcript || "",
        timeTaken: copy[currentQ]?.timeTaken || timer,
      };
      return copy;
    });
  };

  // ENHANCED: Submit interview with analysis data
  const submitInterview = async () => {
    try {
      if (recording) {
        await stopRecording();
        await new Promise((resolve) => setTimeout(resolve, 500));
      }

      setStep(2);
      setFeedback({ loading: true });

      // Ensure current answer is saved
      const currentAnswerValue =
        document.querySelector("textarea")?.value || "";

      const finalAnswers = answers.map((answer, i) => {
        const textValue =
          i === currentQ ? currentAnswerValue : answer?.textAnswer || "";

        return {
          questionNumber: i + 1,
          question: questions[i],
          textAnswer: textValue || answer?.transcript || "",
          transcript: answer?.transcript || "",
          timeTaken: answer?.timeTaken || 0,
          hasVideo: mediaBlobs[i] ? true : false,
          bodyLanguageAnalysis: answer?.bodyLanguageAnalysis || null,
          audioAnalysis: answer?.audioAnalysis || null,
        };
      });

      console.log("üöÄ Submitting interview with answers:", finalAnswers);

      const interviewData = {
        job: selectedJob,
        resume: resume,
        questions: questions,
        answers: finalAnswers,
        totalTime: finalAnswers.reduce(
          (sum, answer) => sum + (answer?.timeTaken || 0),
          0
        ),
        completedAt: new Date().toISOString(),
      };

      const formData = new FormData();
      formData.append("interviewData", JSON.stringify(interviewData));

      mediaBlobs.forEach((blob, index) => {
        formData.append(`video_${index}`, blob, `answer_${index}.webm`);
      });

      let authToken = localStorage.getItem("authToken");

      const res = await fetch(
        `${import.meta.env.VITE_API_URL}/interview/submit`,
        {
          method: "POST",
          headers: {
            ...(authToken && { Authorization: `Bearer ${authToken}` }),
          },
          body: formData,
        }
      );

      if (!res.ok) {
        if (res.status === 401) {
          console.warn("Auth token expired, submitting without authentication");
          const retryRes = await fetch(
            `${import.meta.env.VITE_API_URL}/interview/submit`,
            {
              method: "POST",
              body: formData,
            }
          );

          if (!retryRes.ok) {
            throw new Error(`HTTP error! status: ${retryRes.status}`);
          }

          const data = await retryRes.json();
          setFeedback(data.feedback || data);
          return;
        }
        throw new Error(`HTTP error! status: ${res.status}`);
      }

      const data = await res.json();
      console.log("‚úÖ Interview feedback received:", data);

      setFeedback(data.feedback || data);
    } catch (error) {
      console.error("‚ùå Error submitting interview:", error);

      setFeedback({
        overallFeedback: {
          strengths:
            "You completed the interview successfully and provided thoughtful responses to all questions.",
          weaknesses:
            "Consider providing more specific examples and quantifiable achievements in your answers.",
          tipsForImprovement:
            "Practice speaking more slowly and clearly, and use the STAR method (Situation, Task, Action, Result) for behavioral questions.",
        },
        perQuestion: questions.map((question, i) => ({
          question: question,
          feedback: {
            strengths:
              answers[i]?.textAnswer || answers[i]?.transcript
                ? "You provided a clear response to this question."
                : "You attempted to answer this question.",
            weaknesses: "Could be more detailed and include specific examples.",
            tipsForImprovement:
              "Consider structuring your answer with clear beginning, middle, and end.",
          },
        })),
        score: {
          overall: 75,
          communication: 80,
          technical: 70,
          confidence: 75,
        },
        recommendations: [
          "Practice common interview questions",
          "Prepare specific examples from your experience",
          "Work on speaking clearly and at an appropriate pace",
        ],
      });
    }
  };

  // NEW: Real-time feedback component
  const RealTimeFeedbackPanel = () => (
    <div className="mb-4 p-4 bg-gradient-to-r from-purple-50 to-pink-50 rounded-lg border-l-4 border-purple-400">
      <div className="flex items-center justify-between mb-2">
        <div className="flex items-center gap-2">
          <span className="text-lg">ü§ñ</span>
          <b className="text-purple-800">AI Coach</b>
        </div>
        <Button
          size="sm"
          variant={analysisEnabled ? "destructive" : "default"}
          onClick={() => setAnalysisEnabled(!analysisEnabled)}
        >
          {analysisEnabled ? "üî¥ Disable AI Coach" : "üéØ Enable AI Coach"}
        </Button>
      </div>

      {analysisEnabled && (
        <div className="space-y-3">
          {/* Body Language Metrics */}
          {bodyLanguageAnalysis && (
            <div className="grid grid-cols-2 gap-4">
              <div className="bg-white p-3 rounded-lg">
                <div className="text-sm font-semibold text-gray-600">
                  Posture
                </div>
                <div className="flex items-center gap-2">
                  <div className="text-lg font-bold text-blue-600">
                    {bodyLanguageAnalysis.posture}%
                  </div>
                  <Badge
                    variant={
                      bodyLanguageAnalysis.posture > 75
                        ? "default"
                        : "destructive"
                    }
                  >
                    {bodyLanguageAnalysis.posture > 75 ? "Good" : "Improve"}
                  </Badge>
                </div>
              </div>
              <div className="bg-white p-3 rounded-lg">
                <div className="text-sm font-semibold text-gray-600">
                  Eye Contact
                </div>
                <div className="flex items-center gap-2">
                  <div className="text-lg font-bold text-green-600">
                    {bodyLanguageAnalysis.eyeContact}%
                  </div>
                  <Badge
                    variant={
                      bodyLanguageAnalysis.eyeContact > 70
                        ? "default"
                        : "destructive"
                    }
                  >
                    {bodyLanguageAnalysis.eyeContact > 70 ? "Great" : "Focus"}
                  </Badge>
                </div>
              </div>
            </div>
          )}

          {/* Audio Analysis */}
          {audioAnalysis && (
            <div className="grid grid-cols-2 gap-4">
              <div className="bg-white p-3 rounded-lg">
                <div className="text-sm font-semibold text-gray-600">
                  Voice Tone
                </div>
                <div className="flex items-center gap-2">
                  <div className="text-lg font-bold text-indigo-600">
                    {audioAnalysis.pitch}%
                  </div>
                  <Badge variant="secondary">{audioAnalysis.pace}</Badge>
                </div>
              </div>
              <div className="bg-white p-3 rounded-lg">
                <div className="text-sm font-semibold text-gray-600">
                  Volume
                </div>
                <div className="flex items-center gap-2">
                  <div className="text-lg font-bold text-orange-600">
                    {audioAnalysis.volume}%
                  </div>
                  <Badge
                    variant={
                      audioAnalysis.volume > 40 && audioAnalysis.volume < 80
                        ? "default"
                        : "destructive"
                    }
                  >
                    {audioAnalysis.volume > 40 && audioAnalysis.volume < 80
                      ? "Perfect"
                      : "Adjust"}
                  </Badge>
                </div>
              </div>
            </div>
          )}

          {/* Real-time Feedback */}
          {realTimeFeedback.length > 0 && (
            <div className="bg-yellow-50 p-3 rounded-lg border border-yellow-200">
              <div className="text-sm font-semibold text-yellow-800 mb-2">
                üí° Live Tips:
              </div>
              <ul className="space-y-1">
                {realTimeFeedback.slice(0, 3).map((tip, index) => (
                  <li
                    key={index}
                    className="text-sm text-yellow-700 flex items-center gap-2"
                  >
                    <span className="w-1 h-1 bg-yellow-500 rounded-full"></span>
                    {tip}
                  </li>
                ))}
              </ul>
            </div>
          )}
        </div>
      )}
    </div>
  );

  // EXISTING: Step 0 - Job Selection
  if (step === 0)
    return (
<Card className="max-w-5xl mx-auto mt-6 px-4 md:px-0">
  <CardHeader>
    <CardTitle className="text-2xl font-bold text-primary text-center md:text-left">
      AI Interview Prep
    </CardTitle>
  </CardHeader>
  <CardContent>
    <div className="mb-4 text-muted-foreground text-center md:text-left">
      Select a job to start your mock interview:
    </div>
    <div className="grid gap-3">
      {(Array.isArray(jobs) ? jobs : []).map((job) => {
        const isExpanded = selectedJob?._id === job._id;

        return (
          <div
            key={job._id || job.jobtitle}
            className="border rounded-lg p-3 bg-white shadow-sm"
          >
            {/* Company Name with Chevron */}
            <div
              className="flex justify-between items-center cursor-pointer"
              onClick={() =>
                setSelectedJob(isExpanded ? null : job) // Toggle expansion
              }
            >
              <span className="font-semibold text-lg text-foreground">
                {job.company_name}
              </span>
              {isExpanded ? (
                <ChevronUp className="w-5 h-5 text-muted-foreground" />
              ) : (
                <ChevronDown className="w-5 h-5 text-muted-foreground" />
              )}
            </div>

            {/* Collapsible Job Details */}
            {isExpanded && (
              <div className="mt-3 text-sm text-muted-foreground space-y-2">
                <div>
                  <b>Role:</b> {job.job_title}
                </div>
                <div>
                  <b>Location:</b> {job.location}
                </div>
                <div>
                  <b>Required Skills:</b> {job.required_skills.join(", ")}
                </div>
              </div>
            )}
          </div>
        );
      })}
    </div>
    <Button
      className="mt-6 w-full"
      disabled={!selectedJob}
      onClick={startInterview}
    >
      Start Interview
    </Button>
  </CardContent>
</Card>
    );

  // ENHANCED: Step 1 - Interview with AI Analysis
  if (step === 1)
    return (
      <Card className="max-w-6xl mx-auto mt-6 px-4 md:px-0">
        <CardHeader>
          <CardTitle className="text-xl font-bold text-primary text-center md:text-left">
            üìù Question {currentQ + 1} of {questions.length}
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid lg:grid-cols-3 gap-6">
            {/* Left Column - Video and Controls */}
            <div className="lg:col-span-2">
              <div className="mb-4 text-lg font-medium text-foreground text-center md:text-left">
                {questions[currentQ]}
              </div>
              <video
                ref={videoRef}
                autoPlay
                muted
                className="rounded-lg border mb-4 w-full h-64 object-cover bg-black"
              />

              <div className="flex flex-col md:flex-row items-center gap-4 mb-4">
                <Button
                  onClick={startRecording}
                  disabled={recording}
                  className={recording ? "bg-red-500 hover:bg-red-600" : ""}
                >
                  {recording ? "üî¥ Recording..." : "üé¨ Start Recording"}
                </Button>
                <Button onClick={stopRecording} disabled={!recording}>
                  ‚èπÔ∏è Stop
                </Button>
                <span className="text-muted-foreground">‚è±Ô∏è {timer}s</span>
                {isListening && (
                  <span className="text-green-500 text-sm">
                    üé§ Listening...
                  </span>
                )}
              </div>

              {/* Transcription Display */}
              <div className="mb-4 p-4 bg-gradient-to-r from-blue-50 to-indigo-50 rounded-lg border-l-4 border-blue-400">
                <div className="flex items-center gap-2 mb-2">
                  <span className="text-lg">üé§</span>
                  <b className="text-blue-800">Live Transcription:</b>
                  {isListening && (
                    <span className="animate-pulse text-green-600">‚óè</span>
                  )}
                </div>
                <div className="min-h-[60px] text-gray-800 leading-relaxed">
                  {transcript ? (
                    <span className="whitespace-pre-wrap">{transcript}</span>
                  ) : (
                    <span className="text-gray-400 italic">
                      {recording
                        ? "üéØ Start speaking..."
                        : "Click 'Start Recording' and speak clearly"}
                    </span>
                  )}
                </div>
              </div>

              <textarea
                className="w-full border rounded p-3 mb-4"
                placeholder="‚úçÔ∏è Speak or type your answer..."
                value={answers[currentQ]?.textAnswer || transcript || ""}
                onChange={handleAnswerChange}
                rows={4}
              />
            </div>

            {/* Right Column - AI Analysis */}
            <div className="lg:col-span-1">
              <RealTimeFeedbackPanel />

              {/* Body Language Summary */}
              {bodyLanguageAnalysis && (
                <div className="mb-4 p-4 bg-gradient-to-r from-green-50 to-blue-50 rounded-lg">
                  <h4 className="font-semibold text-gray-800 mb-3">
                    üìä Body Language
                  </h4>
                  <div className="space-y-2 text-sm">
                    <div>
                      Hand Gestures:{" "}
                      <Badge variant="outline">
                        {bodyLanguageAnalysis.handGestures}
                      </Badge>
                    </div>
                    <div>
                      Expression:{" "}
                      <Badge variant="outline">
                        {bodyLanguageAnalysis.facialExpression}
                      </Badge>
                    </div>
                  </div>
                </div>
              )}
            </div>
          </div>

          <div className="flex flex-col md:flex-row justify-between mt-6 gap-4">
            <Button
              variant="outline"
              disabled={currentQ === 0}
              onClick={() => setCurrentQ((q) => q - 1)}
            >
              ‚¨ÖÔ∏è Previous
            </Button>
            {currentQ < questions.length - 1 ? (
              <Button onClick={handleNext}>Next ‚û°Ô∏è</Button>
            ) : (
              <Button
                onClick={submitInterview}
                className="bg-green-600 hover:bg-green-700"
              >
                üéâ Submit Interview
              </Button>
            )}
          </div>
        </CardContent>
      </Card>
    );

  // ENHANCED: Step 2 - Feedback with Body Language Analysis
  if (step === 2)
    return (
      <Card className="max-w-4xl mx-auto mt-6 px-4 md:px-0">
        <CardHeader>
          <CardTitle className="text-xl font-bold text-primary text-center md:text-left">
            üìä Your Interview Feedback
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="mb-6 p-4 bg-green-50 rounded-lg border-l-4 border-green-400">
            <h3 className="font-semibold text-green-800 mb-2">
              üéØ Overall Feedback
            </h3>
            <div className="text-green-700">
              {feedback?.loading ? (
                <div className="flex items-center gap-2">
                  <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-green-700"></div>
                  Analyzing your responses and body language...
                </div>
              ) : typeof feedback?.overallFeedback === "string" ? (
                feedback.overallFeedback
              ) : feedback?.overallFeedback &&
                typeof feedback.overallFeedback === "object" ? (
                <ul className="list-disc ml-4 space-y-1">
                  {feedback.overallFeedback.strengths && (
                    <li>
                      <b>Strengths:</b> {feedback.overallFeedback.strengths}
                    </li>
                  )}
                  {feedback.overallFeedback.weaknesses && (
                    <li>
                      <b>Areas to Improve:</b>{" "}
                      {feedback.overallFeedback.weaknesses}
                    </li>
                  )}
                  {feedback.overallFeedback.tipsForImprovement && (
                    <li>
                      <b>Tips:</b> {feedback.overallFeedback.tipsForImprovement}
                    </li>
                  )}
                </ul>
              ) : (
                "Great job completing the interview!"
              )}
            </div>
          </div>

          {/* NEW: Body Language Summary */}
          {!feedback?.loading &&
            answers.some((a) => a.bodyLanguageAnalysis) && (
              <div className="mb-6 p-4 bg-purple-50 rounded-lg border-l-4 border-purple-400">
                <h3 className="font-semibold text-purple-800 mb-3">
                  ü§ñ Body Language & Tone Analysis
                </h3>
                <div className="grid md:grid-cols-2 gap-4">
                  <div className="bg-white p-4 rounded-lg">
                    <h4 className="font-semibold mb-2">üìê Average Scores</h4>
                    <div className="space-y-2">
                      {answers.filter((a) => a.bodyLanguageAnalysis).length >
                        0 && (
                        <>
                          <div className="flex justify-between">
                            <span>Posture:</span>
                            <Badge>
                              {Math.round(
                                answers
                                  .filter((a) => a.bodyLanguageAnalysis)
                                  .reduce(
                                    (sum, a) =>
                                      sum + a.bodyLanguageAnalysis.posture,
                                    0
                                  ) /
                                  answers.filter((a) => a.bodyLanguageAnalysis)
                                    .length
                              )}
                              %
                            </Badge>
                          </div>
                          <div className="flex justify-between">
                            <span>Eye Contact:</span>
                            <Badge>
                              {Math.round(
                                answers
                                  .filter((a) => a.bodyLanguageAnalysis)
                                  .reduce(
                                    (sum, a) =>
                                      sum + a.bodyLanguageAnalysis.eyeContact,
                                    0
                                  ) /
                                  answers.filter((a) => a.bodyLanguageAnalysis)
                                    .length
                              )}
                              %
                            </Badge>
                          </div>
                        </>
                      )}
                    </div>
                  </div>
                  <div className="bg-white p-4 rounded-lg">
                    <h4 className="font-semibold mb-2">üéµ Voice Analysis</h4>
                    <div className="space-y-2 text-sm">
                      <div>
                        Most common pace: <Badge variant="outline">Good</Badge>
                      </div>
                      <div>
                        Tone consistency:{" "}
                        <Badge variant="outline">Stable</Badge>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            )}

          {!feedback?.loading && (
            <div className="space-y-4">
              <h3 className="font-semibold text-lg">
                üìù Question-by-Question Analysis
              </h3>
              {(Array.isArray(feedback?.perQuestion)
                ? feedback.perQuestion
                : []
              ).map((q, i) => (
                <div key={i} className="bg-gray-50 rounded-lg p-4 border">
                  <div className="font-semibold text-gray-800 mb-2">
                    ‚ùì {q.question}
                  </div>

                  {/* Answer and body language data */}
                  <div className="grid md:grid-cols-2 gap-4 mb-3">
                    <div className="text-sm text-blue-900 p-2 bg-blue-50 rounded">
                      <b>Your answer:</b>{" "}
                      {answers[i]?.textAnswer || answers[i]?.transcript || (
                        <span className="italic text-gray-500">
                          No text recorded
                        </span>
                      )}
                    </div>

                    {answers[i]?.bodyLanguageAnalysis && (
                      <div className="text-sm p-2 bg-purple-50 rounded">
                        <b>Body Language:</b>
                        <div className="mt-1 flex gap-2">
                          <Badge size="sm">
                            Posture: {answers[i].bodyLanguageAnalysis.posture}%
                          </Badge>
                          <Badge size="sm" variant="outline">
                            {answers[i].bodyLanguageAnalysis.handGestures}
                          </Badge>
                        </div>
                      </div>
                    )}
                  </div>

                  <div className="text-gray-700">
                    <b>üí° Feedback:</b>{" "}
                    {typeof q.feedback === "string" ? (
                      q.feedback
                    ) : q.feedback && typeof q.feedback === "object" ? (
                      <ul className="list-disc ml-4 mt-1">
                        {q.feedback.strengths && (
                          <li>
                            <b>Strengths:</b> {q.feedback.strengths}
                          </li>
                        )}
                        {q.feedback.weaknesses && (
                          <li>
                            <b>Improve:</b> {q.feedback.weaknesses}
                          </li>
                        )}
                        {q.feedback.tipsForImprovement && (
                          <li>
                            <b>Tips:</b> {q.feedback.tipsForImprovement}
                          </li>
                        )}
                      </ul>
                    ) : (
                      "Good response!"
                    )}
                  </div>
                </div>
              ))}
            </div>
          )}

          <Button className="mt-6 w-full" onClick={() => setStep(0)}>
            üîÑ Try Another Interview
          </Button>
        </CardContent>
      </Card>
    );
};

export default InterviewPrep;
